{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LSMI Evaluation Notebook\n",
                "\n",
                "This notebook evaluates the IlluminantCNN model on the balanced LSMI test set.\n",
                "It performs the following:\n",
                "1.  Loads the pre-trained model.\n",
                "2.  Runs inference on the test images.\n",
                "3.  Generates Grad-CAM heatmaps for each illuminant cluster.\n",
                "4.  Calculates metrics (IOU, DICE, P-MAE) against the Ground Truth masks.\n",
                "5.  Visualizes the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "8b7b94bc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/adnanamir/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
                        "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "from torchvision import transforms\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "import pandas as pd\n",
                "\n",
                "# Import Models\n",
                "from illuminant_estimation.models.cnn import IlluminantCNN, IllumiCam3, ConfidenceWeightedCNN, ColorConstancyCNN\n",
                "\n",
                "# Import CAM Methods\n",
                "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, ScoreCAM\n",
                "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
                "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
                "\n",
                "# Import Test Package Utils\n",
                "import sys\n",
                "sys.path.append(\"LSMI_Test_Package\")\n",
                "from lsmi_utils import process_raw_image, load_mask, get_cluster_names\n",
                "\n",
                "# Constants\n",
                "TEST_PACKAGE_DIR = \"LSMI_Test_Package\"\n",
                "IMAGES_DIR = os.path.join(TEST_PACKAGE_DIR, \"images\")\n",
                "MASKS_DIR = os.path.join(TEST_PACKAGE_DIR, \"masks\")\n",
                "MODEL_PATH = \"best_illuminant_cnn_val_8084.pth\" # Update with your model path\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "CLUSTER_NAMES = get_cluster_names()\n",
                "\n",
                "print(f\"Using device: {DEVICE}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc8fa05d",
            "metadata": {},
            "source": [
                "## 1. Load Model\n",
                "Load the pre-trained IlluminantCNN model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f142c73",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_model(model_name, model_path):\n",
                "    print(f\"Loading model architecture: {model_name}\")\n",
                "    \n",
                "    if model_name == \"IlluminantCNN\":\n",
                "        model = IlluminantCNN(num_classes=5)\n",
                "    elif model_name == \"IllumiCam3\":\n",
                "        model = IllumiCam3(num_classes=5)\n",
                "    elif model_name == \"ConfidenceWeightedCNN\":\n",
                "        model = ConfidenceWeightedCNN(num_classes=5)\n",
                "    elif model_name == \"ColorConstancyCNN\":\n",
                "        model = ColorConstancyCNN(K=5, pretrained=False) # Pretrained=False to avoid loading ImageNet weights if we load state_dict\n",
                "    else:\n",
                "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
                "        \n",
                "    model = model.to(DEVICE)\n",
                "    \n",
                "    if os.path.exists(model_path):\n",
                "        try:\n",
                "            # Try loading state dict\n",
                "            state_dict = torch.load(model_path, map_location=DEVICE)\n",
                "            model.load_state_dict(state_dict, strict=False) # strict=False to handle potential minor mismatches (e.g. ImageNet weights)\n",
                "            print(f\"Loaded weights from {model_path}\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error loading weights: {e}\")\n",
                "            print(\"Using random/initialized weights.\")\n",
                "    else:\n",
                "        print(f\"Model file not found at {model_path}. Using random/initialized weights.\")\n",
                "        \n",
                "    model.eval()\n",
                "    return model\n",
                "\n",
                "# Configuration\n",
                "MODEL_NAME = \"IlluminantCNN\" # Options: IlluminantCNN, IllumiCam3, ConfidenceWeightedCNN, ColorConstancyCNN\n",
                "CAM_METHOD_NAME = \"GradCAMPlusPlus\" # Options: GradCAM, GradCAMPlusPlus, ScoreCAM\n",
                "\n",
                "model = load_model(MODEL_NAME, MODEL_PATH)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4f49c8e5",
            "metadata": {},
            "source": [
                "## 2. Define Metrics\n",
                "We define the metrics for evaluating the predicted masks (Grad-CAMs) against the Ground Truth masks.\n",
                "\n",
                "- **IOU (Intersection over Union)**: `TP / (TP + FP + FN)`\n",
                "- **DICE Score**: `2 * TP / (2 * TP + FP + FN)`\n",
                "- **P-MAE (Pixel-level Mean Absolute Error)**: `mean(|GT - Pred|)`\n",
                "\n",
                "Note: GT masks are continuous probabilities (0-1). Grad-CAMs are also normalized to 0-1. For IOU and DICE, we threshold them (e.g., > 0.5)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aaa0106b",
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_metrics(gt_mask, pred_mask, gt_threshold=0.5, pred_threshold=0.5):\n",
                "    \"\"\"\n",
                "    Calculates IOU, DICE, and MAE.\n",
                "    IOU and DICE are calculated on binary masks created by thresholding GT and Pred.\n",
                "    MAE is calculated on continuous values.\n",
                "    \"\"\"\n",
                "    \n",
                "    # MAE (on continuous values)\n",
                "    mae = np.mean(np.abs(gt_mask - pred_mask))\n",
                "    \n",
                "    # Threshold for IOU/DICE\n",
                "    gt_bin = (gt_mask > gt_threshold).astype(bool)\n",
                "    pred_bin = (pred_mask > pred_threshold).astype(bool)\n",
                "    \n",
                "    intersection = np.logical_and(gt_bin, pred_bin).sum()\n",
                "    union = np.logical_or(gt_bin, pred_bin).sum()\n",
                "    \n",
                "    if union == 0:\n",
                "        iou = 1.0 if intersection == 0 else 0.0\n",
                "    else:\n",
                "        iou = intersection / union\n",
                "        \n",
                "    dice_denom = gt_bin.sum() + pred_bin.sum()\n",
                "    if dice_denom == 0:\n",
                "        dice = 1.0 if intersection == 0 else 0.0\n",
                "    else:\n",
                "        dice = 2 * intersection / dice_denom\n",
                "        \n",
                "    return iou, dice, mae\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8c26cc50",
            "metadata": {},
            "source": [
                "## 3. Evaluation Loop\n",
                "Run inference on all test images, generate Grad-CAMs for all clusters, and calculate metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "721c7dcf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup CAM\n",
                "def get_cam(model, model_name, method_name):\n",
                "    # Determine target layers based on model architecture\n",
                "    if model_name == \"IlluminantCNN\":\n",
                "        target_layers = [model.conv5]\n",
                "    elif model_name == \"IllumiCam3\":\n",
                "        target_layers = [model.conv5]\n",
                "    elif model_name == \"ConfidenceWeightedCNN\":\n",
                "        target_layers = [model.conv5] # Last shared conv layer\n",
                "    elif model_name == \"ColorConstancyCNN\":\n",
                "        # Target the last convolutional layer of AlexNet features\n",
                "        # model.features is Sequential. Index 10 is Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
                "        target_layers = [model.features[10]] \n",
                "    else:\n",
                "        target_layers = [list(model.modules())[-1]] # Fallback\n",
                "\n",
                "    if method_name == \"GradCAM\":\n",
                "        return GradCAM(model=model, target_layers=target_layers)\n",
                "    elif method_name == \"GradCAMPlusPlus\":\n",
                "        return GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
                "    elif method_name == \"ScoreCAM\":\n",
                "        return ScoreCAM(model=model, target_layers=target_layers)\n",
                "    else:\n",
                "        raise ValueError(f\"Unknown CAM method: {method_name}\")\n",
                "\n",
                "cam = get_cam(model, MODEL_NAME, CAM_METHOD_NAME)\n",
                "print(f\"Using CAM Method: {CAM_METHOD_NAME} on {MODEL_NAME}\")\n",
                "\n",
                "# Transforms for model input\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Configurable Thresholds\n",
                "GT_THRESHOLD = 0.5\n",
                "PRED_THRESHOLD = 0.5\n",
                "\n",
                "print(f\"Using GT Threshold: {GT_THRESHOLD}\")\n",
                "print(f\"Using Pred Threshold: {PRED_THRESHOLD}\")\n",
                "\n",
                "results = []\n",
                "\n",
                "# Get list of test scenes\n",
                "test_scenes = [f.replace(\".nef\", \"\") for f in os.listdir(IMAGES_DIR) if f.endswith(\".nef\")]\n",
                "print(f\"Evaluating on {len(test_scenes)} scenes...\")\n",
                "\n",
                "for scene_id in tqdm(test_scenes):\n",
                "    try:\n",
                "        # Load Image\n",
                "        img_path = os.path.join(IMAGES_DIR, f\"{scene_id}.nef\")\n",
                "        \n",
                "        # Load Raw for Model Input (Linear RGB)\n",
                "        img_raw = process_raw_image(img_path, srgb=False)\n",
                "        \n",
                "        # Load sRGB for Visualization/Mask Reference\n",
                "        img_rgb = process_raw_image(img_path, srgb=True)\n",
                "        \n",
                "        # Prepare for Model (Use Raw)\n",
                "        img_pil = Image.fromarray(img_raw)\n",
                "        input_tensor = transform(img_pil).unsqueeze(0).to(DEVICE)\n",
                "        \n",
                "        # Load GT Mask\n",
                "        mask_path = os.path.join(MASKS_DIR, f\"{scene_id}_mask.npy\")\n",
                "        gt_mask = load_mask(mask_path, target_shape=img_rgb.shape)\n",
                "        \n",
                "        # Generate CAM for each cluster\n",
                "        scene_metrics = {'scene': scene_id}\n",
                "        \n",
                "        for i, cluster_name in enumerate(CLUSTER_NAMES):\n",
                "            # Get GT channel\n",
                "            gt_channel = gt_mask[:, :, i]\n",
                "            \n",
                "            # Skip if GT is empty\n",
                "            if gt_channel.max() == 0:\n",
                "                continue\n",
                "            \n",
                "            targets = [ClassifierOutputTarget(i)]\n",
                "            grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
                "            \n",
                "            # Resize CAM to original image size\n",
                "            pred_mask = cv2.resize(grayscale_cam, (img_rgb.shape[1], img_rgb.shape[0]))\n",
                "            \n",
                "            # Calculate Metrics\n",
                "            iou, dice, mae = calculate_metrics(gt_channel, pred_mask, gt_threshold=GT_THRESHOLD, pred_threshold=PRED_THRESHOLD)\n",
                "            \n",
                "            scene_metrics[f'{cluster_name}_IOU'] = iou\n",
                "            scene_metrics[f'{cluster_name}_DICE'] = dice\n",
                "            scene_metrics[f'{cluster_name}_MAE'] = mae\n",
                "            \n",
                "        results.append(scene_metrics)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {scene_id}: {e}\")\n",
                "\n",
                "df_results = pd.DataFrame(results)\n",
                "print(\"Evaluation Complete.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c013f8a6",
            "metadata": {},
            "source": [
                "## 4. Results Summary\n",
                "Average metrics across the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "218adad1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate averages\n",
                "summary = {}\n",
                "for metric in ['IOU', 'DICE', 'MAE']:\n",
                "    for cluster in CLUSTER_NAMES:\n",
                "        col = f'{cluster}_{metric}'\n",
                "        if col in df_results.columns:\n",
                "            summary[col] = df_results[col].mean()\n",
                "\n",
                "print(\"Average Metrics:\")\n",
                "for cluster in CLUSTER_NAMES:\n",
                "    print(f\"\\nCluster: {cluster}\")\n",
                "    print(f\"  IOU:  {summary.get(f'{cluster}_IOU', 0):.4f}\")\n",
                "    print(f\"  DICE: {summary.get(f'{cluster}_DICE', 0):.4f}\")\n",
                "    print(f\"  MAE:  {summary.get(f'{cluster}_MAE', 0):.4f}\")\n",
                "\n",
                "# Overall Average\n",
                "print(\"\\nOverall Averages:\")\n",
                "print(f\"  mIOU: {np.mean([summary[f'{c}_IOU'] for c in CLUSTER_NAMES]):.4f}\")\n",
                "print(f\"  mDICE: {np.mean([summary[f'{c}_DICE'] for c in CLUSTER_NAMES]):.4f}\")\n",
                "print(f\"  mMAE: {np.mean([summary[f'{c}_MAE'] for c in CLUSTER_NAMES]):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comprehensive Evaluation Matrix\n",
                "# Runs trials on all combinations (4 Models x 3 CAMs)\n",
                "# Weights: Specific weights for each model\n",
                "# Thresholds: GT=0, Pred=0.1\n",
                "\n",
                "# Configuration\n",
                "MODELS = {\n",
                "    \"IlluminantCNN\": \"best_illuminant_cnn_val_8084.pth\",\n",
                "    \"IllumiCam3\": \"illumicam3.pth\",\n",
                "    \"ColorConstancyCNN\": \"best_paper_model.pth\",\n",
                "    \"ConfidenceWeightedCNN\": \"best_illuminant_cnn_confidence.pth\"\n",
                "}\n",
                "\n",
                "CAM_METHODS = [\"GradCAM\", \"GradCAMPlusPlus\", \"ScoreCAM\"]\n",
                "\n",
                "# Thresholds\n",
                "MATRIX_GT_THRESHOLD = 0.0\n",
                "MATRIX_PRED_THRESHOLD = 0.1\n",
                "\n",
                "matrix_results = []\n",
                "\n",
                "print(\"Starting Comprehensive Evaluation Matrix...\")\n",
                "print(f\"GT Threshold: {MATRIX_GT_THRESHOLD}, Pred Threshold: {MATRIX_PRED_THRESHOLD}\")\n",
                "\n",
                "for model_name, model_path in MODELS.items():\n",
                "    print(f\"\\nEvaluating Model: {model_name}\")\n",
                "    \n",
                "    # Load Model\n",
                "    try:\n",
                "        # Note: load_model and get_cam must be defined in previous cells\n",
                "        model = load_model(model_name, model_path)\n",
                "    except Exception as e:\n",
                "        print(f\"Failed to load {model_name}: {e}\")\n",
                "        continue\n",
                "        \n",
                "    for cam_method in CAM_METHODS:\n",
                "        print(f\"  Using CAM: {cam_method}\")\n",
                "        \n",
                "        try:\n",
                "            cam = get_cam(model, model_name, cam_method)\n",
                "        except Exception as e:\n",
                "            print(f\"  Failed to init {cam_method}: {e}\")\n",
                "            continue\n",
                "            \n",
                "        # Accumulate metrics for this combination\n",
                "        combo_metrics = {\n",
                "            \"Model\": model_name,\n",
                "            \"CAM\": cam_method,\n",
                "            \"mIOU\": [],\n",
                "            \"mDICE\": [],\n",
                "            \"mMAE\": []\n",
                "        }\n",
                "        \n",
                "        # Run Inference on all scenes\n",
                "        for scene_id in tqdm(test_scenes, desc=f\"{model_name}-{cam_method}\", leave=False):\n",
                "            try:\n",
                "                # Load Data (Raw for Input, sRGB for shape)\n",
                "                img_path = os.path.join(IMAGES_DIR, f\"{scene_id}.nef\")\n",
                "                img_raw = process_raw_image(img_path, srgb=False)\n",
                "                img_rgb = process_raw_image(img_path, srgb=True) # For shape/mask target\n",
                "                \n",
                "                img_pil = Image.fromarray(img_raw)\n",
                "                input_tensor = transform(img_pil).unsqueeze(0).to(DEVICE)\n",
                "                \n",
                "                mask_path = os.path.join(MASKS_DIR, f\"{scene_id}_mask.npy\")\n",
                "                gt_mask = load_mask(mask_path, target_shape=img_rgb.shape)\n",
                "                \n",
                "                scene_ious = []\n",
                "                scene_dices = []\n",
                "                scene_maes = []\n",
                "                \n",
                "                for i, cluster_name in enumerate(CLUSTER_NAMES):\n",
                "                    gt_channel = gt_mask[:, :, i]\n",
                "                    if gt_channel.max() == 0: continue\n",
                "                    \n",
                "                    targets = [ClassifierOutputTarget(i)]\n",
                "                    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
                "                    pred_mask = cv2.resize(grayscale_cam, (img_rgb.shape[1], img_rgb.shape[0]))\n",
                "                    \n",
                "                    # Calculate Metrics with Matrix Thresholds\n",
                "                    iou, dice, mae = calculate_metrics(gt_channel, pred_mask, gt_threshold=MATRIX_GT_THRESHOLD, pred_threshold=MATRIX_PRED_THRESHOLD)\n",
                "                    \n",
                "                    scene_ious.append(iou)\n",
                "                    scene_dices.append(dice)\n",
                "                    scene_maes.append(mae)\n",
                "                \n",
                "                if scene_ious:\n",
                "                    combo_metrics[\"mIOU\"].append(np.mean(scene_ious))\n",
                "                    combo_metrics[\"mDICE\"].append(np.mean(scene_dices))\n",
                "                    combo_metrics[\"mMAE\"].append(np.mean(scene_maes))\n",
                "                    \n",
                "            except Exception as e:\n",
                "                # print(f\"Error on {scene_id}: {e}\")\n",
                "                pass \n",
                "        \n",
                "        # Average over all scenes\n",
                "        res = {\n",
                "            \"Model\": model_name,\n",
                "            \"CAM\": cam_method,\n",
                "            \"mIOU\": np.mean(combo_metrics[\"mIOU\"]) if combo_metrics[\"mIOU\"] else 0,\n",
                "            \"mDICE\": np.mean(combo_metrics[\"mDICE\"]) if combo_metrics[\"mDICE\"] else 0,\n",
                "            \"mMAE\": np.mean(combo_metrics[\"mMAE\"]) if combo_metrics[\"mMAE\"] else 0\n",
                "        }\n",
                "        matrix_results.append(res)\n",
                "        print(f\"    -> mIOU: {res['mIOU']:.4f}, mDICE: {res['mDICE']:.4f}, mMAE: {res['mMAE']:.4f}\")\n",
                "\n",
                "# Display Results\n",
                "df_matrix = pd.DataFrame(matrix_results)\n",
                "print(\"\\nEvaluation Matrix Results:\")\n",
                "try:\n",
                "    display(df_matrix)\n",
                "except NameError:\n",
                "    print(df_matrix)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
