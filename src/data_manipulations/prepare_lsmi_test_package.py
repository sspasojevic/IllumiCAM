import os
import shutil
import json
import pandas as pd
import numpy as np
from tqdm import tqdm
import argparse
import rawpy
import sys

# Import generation logic
try:
    import generate_lsmi_mixture_maps
except ImportError:
    # Assuming it's in the same directory
    sys.path.append(os.getcwd())
    import generate_lsmi_mixture_maps

# Add repo root to path to import config
# Assuming we are in IllumiCAM/src/data_manipulations
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__)) # .../src/data_manipulations
REPO_ROOT = os.path.dirname(os.path.dirname(SCRIPT_DIR)) # .../IllumiCAM
sys.path.insert(0, REPO_ROOT)

from config.config import LSMI_DATASET_ROOT

# Import generation logic if needed, or just reimplement simple check
# We will assume the masks are already generated by the previous script, 
# but we can include a check.

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--csv", default="lsmi_balanced.csv", help="Path to balanced CSV")
    parser.add_argument("--src_root", default=os.path.join(LSMI_DATASET_ROOT, "nikon"), help="Source dataset path")
    parser.add_argument("--output_dir", default="LSMI_Test_Package", help="Output package path")
    parser.add_argument("--meta", default=os.path.join(LSMI_DATASET_ROOT, "nikon", "meta.json"), help="Path to original meta.json")
    args = parser.parse_args()

    # Create output directories
    images_dir = os.path.join(args.output_dir, "images")
    masks_dir = os.path.join(args.output_dir, "masks")
    os.makedirs(images_dir, exist_ok=True)
    os.makedirs(masks_dir, exist_ok=True)

    # Read CSV
    print(f"Reading {args.csv}...")
    df = pd.read_csv(args.csv)
    target_places = df['place'].unique()
    print(f"Found {len(target_places)} unique places in CSV.")

    # Read Meta
    print(f"Reading {args.meta}...")
    with open(args.meta, 'r') as f:
        full_meta = json.load(f)

    subset_meta = {}
    
    # Process each place
    print("Processing places...")
    for place in tqdm(target_places):
        if place not in full_meta:
            print(f"Warning: {place} not found in meta.json. Skipping.")
            continue

        place_info = full_meta[place]
        num_lights = place_info["NumOfLights"]
        
        # Filter for 2 or 3 illuminants as requested (though CSV implies they are relevant)
        if num_lights not in [2, 3]:
            print(f"Skipping {place}: NumOfLights is {num_lights}")
            continue

        # Add to subset meta
        subset_meta[place] = place_info

        # Source directory
        src_place_dir = os.path.join(args.src_root, place)
        if not os.path.exists(src_place_dir):
            print(f"Warning: Directory {src_place_dir} not found.")
            continue

        # Files to copy
        # Mask
        src_mask = os.path.join(src_place_dir, f"{place}_mixture.npy")
        dst_mask = os.path.join(masks_dir, f"{place}.npy")
        
        # Generate mask if missing
        if not os.path.exists(src_mask):
             print(f"Mask {src_mask} missing. Generating...")
             generate_lsmi_mixture_maps.process_place(src_place_dir, place, place_info)
        
        if os.path.exists(src_mask):
            shutil.copy2(src_mask, dst_mask)
        else:
            print(f"Error: Failed to generate mask for {place}")

        # Image
        src_image = None
        if num_lights == 2:
            src_image = os.path.join(src_place_dir, f"{place}_12.nef")
        elif num_lights == 3:
            src_image = os.path.join(src_place_dir, f"{place}_123.nef")
            
        if src_image and os.path.exists(src_image):
            dst_image = os.path.join(images_dir, f"{place}.nef")
            shutil.copy2(src_image, dst_image)
        else:
            print(f"Warning: Image {src_image} missing.")

    # Save subset meta
    print("Saving subset meta.json...")
    with open(os.path.join(args.output_dir, "meta.json"), 'w') as f:
        json.dump(subset_meta, f, indent=4)

    # Copy cluster centers
    cluster_src = "cluster_centers.npy" # Assuming in CWD
    if os.path.exists(cluster_src):
        shutil.copy2(cluster_src, os.path.join(args.output_dir, "cluster_centers.npy"))
    else:
        print("Warning: cluster_centers.npy not found in current directory.")

    # Create README
    print("Creating README.md...")
    readme_content = """# LSMI Test Package

This package contains a subset of the LSMI dataset (Nikon) for testing illuminant estimation and white balancing.

## Contents

- **meta.json**: Metadata for the included scenes (illuminant colors, MCC coordinates, etc.).
- **cluster_centers.npy**: Cluster centers for illuminant mapping.
- **images/**: Directory containing the raw images.
    - **PlaceX.nef**: The raw image with mixed illumination (2 or 3 lights).
- **masks/**: Directory containing the ground truth masks.
    - **PlaceX.npy**: The ground truth illuminant mixture map.

## How to use

### Loading the Data

1. **Load the Raw Image**:
   Use `rawpy` to load the `.nef` file.
   ```python
   import rawpy
   with rawpy.imread("images/PlaceX.nef") as raw:
       # Process to linear RGB for analysis
       rgb = raw.postprocess(gamma=(1,1), no_auto_bright=True, output_bps=16, user_wb=[1,1,1,1], user_black=0)
   ```

2. **Load the Mask**:
   Load the `.npy` file.
   ```python
   import numpy as np
   mask = np.load("masks/PlaceX.npy")
   # Shape: (H, W, NumLights)
   # Values: 0.0 to 1.0 (summing to 1.0 across channels)
   ```

### White Balancing

To white balance the image using the ground truth masks and illuminant colors:

1. **Get Illuminant Colors**:
   Read `meta.json` for the place.
   ```python
   import json
   with open("meta.json") as f:
       meta = json.load(f)
   
   place_info = meta["PlaceX"]
   light1_chroma = place_info["Light1"] # [r, g, b] (normalized to G=1 usually)
   light2_chroma = place_info["Light2"]
   ```

2. **Apply Pixel-wise WB**:
   The observed color $I$ at a pixel is a mixture of illuminants $L_k$ reflected by surface reflectance $R$.
   $I = R \\times \\sum (w_k \\times L_k)$
   
   To correct it, we want to estimate $R$.
   If we know the weights $w_k$ (from the mask) and lights $L_k$, the effective illuminant at that pixel is $L_{eff} = \\sum (w_k \\times L_k)$.
   
   The white balanced pixel value would be $I / L_{eff}$.
   
   *Note: This is a simplified diagonal model. Ensure dimensions match.*

   ```python
   # Construct effective illuminant map
   h, w, c = mask.shape
   l_eff = np.zeros((h, w, 3))
   
   l_eff += mask[:,:,0][:,:,None] * light1_chroma
   l_eff += mask[:,:,1][:,:,None] * light2_chroma
   # ... add light 3 if exists
   
   # Apply correction (assuming linear RGB image 'img')
   # Avoid division by zero
   img_wb = img / np.clip(l_eff, 1e-6, None)
   ```

"""
    with open(os.path.join(args.output_dir, "README.md"), 'w') as f:
        f.write(readme_content)

    print("Done!")

if __name__ == "__main__":
    main()
